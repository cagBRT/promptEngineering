{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPilAClw4+MaFfAXbjglgHj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/promptEngineering/blob/main/Encoder_Decoder_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook gives examples of implementing Encoder models"
      ],
      "metadata": {
        "id": "ovFhUGtN5U5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -s https://github.com/cagBRT/promptEngineering.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "metadata": {
        "id": "xnjoiN8b34zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "id": "tv4-sNch3-jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig, EncoderDecoderConfig, EncoderDecoderModel"
      ],
      "metadata": {
        "id": "0Ir3roHQ56Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configure the encoder and decoder**"
      ],
      "metadata": {
        "id": "SHNtxdu-5-pb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPLps1EJ3vds"
      },
      "outputs": [],
      "source": [
        "config_encoder = BertConfig()\n",
        "config_decoder = BertConfig()\n",
        "\n",
        "config = EncoderDecoderConfig.from_encoder_decoder_configs(config_encoder, config_decoder)\n",
        "model = EncoderDecoderModel(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizer"
      ],
      "metadata": {
        "id": "3LB5QvF16FP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Select a tokenizer**<br><br>\n",
        "**BertTokenizer**:\n",
        "BERT uses what is called a WordPiece tokenizer. It works by splitting words either into the full forms (e.g., one word becomes one token) or into word pieces â€” where one word can be broken into multiple tokens. An example of where this can be useful is where we have multiple forms of words.<br><br>\n",
        "BERT's creators noted a significant decrease in performance when using documents longer than 512 tokens. So, this limit was put to guard against low quality output"
      ],
      "metadata": {
        "id": "-sRSEK4S6Hbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "8a9CaP7o4M3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, EncoderDecoderModel"
      ],
      "metadata": {
        "id": "N14YFcWH69u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**patrickvonplaten/bert2bert_cnn_daily_mail**<br><br>\n",
        "This model is a warm-started BERT2BERT model fine-tuned on the CNN/Dailymail summarization dataset."
      ],
      "metadata": {
        "id": "UYJAQpVL7AwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load a fine-tuned seq2seq model and corresponding tokenizer\n",
        "model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")"
      ],
      "metadata": {
        "id": "MNDTRg2V68CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's perform inference on a long piece of text\n",
        "ARTICLE_TO_SUMMARIZE = (\n",
        "    \"PG&E stated it scheduled the blackouts in response to forecasts for high winds \"\n",
        "    \"amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were \"\n",
        "    \"scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\n",
        ")\n",
        "input_ids = tokenizer(ARTICLE_TO_SUMMARIZE, return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "hXWnJxYv4Pok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autoregressive models** predict future values based on past values. <br><br>\n",
        "For example: they are widely used in technical analysis to forecast future security prices."
      ],
      "metadata": {
        "id": "nDhi4djQ71bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# autoregressively generate summary (uses greedy decoding by default)\n",
        "generated_ids = model.generate(input_ids)\n",
        "generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "0BISXFkr9Caf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model summarized the text<br>\n",
        "Look at the summary the model generated.Would you comsider this a good summary?\n"
      ],
      "metadata": {
        "id": "hJJZqr6Q8QV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8zbdRjDj9Yfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_text)"
      ],
      "metadata": {
        "id": "uLlIhpaM9ERl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's perform inference on a long piece of text\n",
        "ARTICLE_TO_SUMMARIZE = (\n",
        "    \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building,\"\n",
        "    \"and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on \"\n",
        "    \"each side. During its construction, the Eiffel Tower surpassed the Washington Monument to \"\n",
        "    \"become the tallest man-made structure in the world, a title it held for 41 years until the\"\n",
        "    \"Chrysler Building in New York City was finished in 1930. It was the first structure to reach\"\n",
        "    \"a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower\"\n",
        "    \"in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). \"\n",
        "    \"Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France\"\n",
        "    \"after the Millau Viaduct.\"\n",
        ")\n",
        "input_ids = tokenizer(ARTICLE_TO_SUMMARIZE, return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "QvMs_PE88eAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# autoregressively generate summary (uses greedy decoding by default)\n",
        "generated_ids = model.generate(input_ids)\n",
        "generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "VYVsuty17f-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What do you think of this summary?**<br>\n",
        "Does this example illustrate how these transformation models can make mistakes?"
      ],
      "metadata": {
        "id": "GjK-1TQB-Atx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_text)"
      ],
      "metadata": {
        "id": "XnYJF2dC7lO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment:** <br>\n",
        "Find a block of text and see the model summarizes it. <br>\n",
        "Is there any pattern to the text segments the model selects for the summary?"
      ],
      "metadata": {
        "id": "gePdehGn-uZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MaLCjCUu9daL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a workaround to load from pytorch checkpoint\n",
        "from transformers import EncoderDecoderModel, TFEncoderDecoderModel\n",
        "\n",
        "_model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/bert2bert-cnn_dailymail-fp16\")\n",
        "\n",
        "_model.encoder.save_pretrained(\"./encoder\")\n",
        "_model.decoder.save_pretrained(\"./decoder\")\n",
        "\n",
        "model = TFEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
        "    \"./encoder\", \"./decoder\", encoder_from_pt=True, decoder_from_pt=True\n",
        ")\n",
        "# This is only for copying some specific attributes of this particular model.\n",
        "model.config = _model.config"
      ],
      "metadata": {
        "id": "tQmJYjL54X_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, EncoderDecoderModel"
      ],
      "metadata": {
        "id": "0DkaClrX_TAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Select the tokenizer**<br>\n",
        "**And configure the model**"
      ],
      "metadata": {
        "id": "NXPUCO2H_XDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")\n",
        "\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "id": "ufBxYwF9_Vnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(\n",
        "    \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building,\"\n",
        "    \" and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side.\"\n",
        "    \"During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest \"\n",
        "    \"man-made structure in the world, a title it held for 41 years until the Chrysler Building in \"\n",
        "    \"New York City was  finished in 1930. It was the first structure to reach a height of 300 metres.\"\n",
        "    \"Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than\"\n",
        "    \"the Chrysler Building by 5.2 metres (17 ft).Excluding transmitters, the Eiffel Tower is the second\"\n",
        "    \" tallest free-standing structure in France after the Millau Viaduct.\",\n",
        "    return_tensors=\"pt\",\n",
        ").input_ids"
      ],
      "metadata": {
        "id": "hPDPzO94_idT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the model is created, it can be fine-tuned similar to BART, T5 or any other encoder-decoder model. <br><br>\n",
        "**Only 2 inputs are required for the model in order to compute a loss**:\n",
        "- input_ids (which are the input_ids of the encoded input sequence)\n",
        "- labels (which are the input_ids of the encoded target sequence)."
      ],
      "metadata": {
        "id": "mFEfy-Oj__ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = tokenizer(\n",
        "    \"the eiffel tower surpassed the washington monument to become the tallest structure in the world. it was the first structure to reach a height of 300 metres in paris in 1930. it is now taller than the chrysler building by 5. 2 metres ( 17 ft ) and is the second tallest free - standing structure in paris.\",\n",
        "    return_tensors=\"pt\",\n",
        ").input_ids\n",
        "\n",
        "# the forward function automatically creates the correct decoder_input_ids\n",
        "loss = model(input_ids=input_ids, labels=labels).loss"
      ],
      "metadata": {
        "id": "zObgrQD54hnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A loss function guides the training algorithm to update parameters in the right way. In a much simple definition, a loss function takes a truth (y) and a prediction (Å·) as input and gives a score of real value number. This value indicates how much the prediction is close to the truth."
      ],
      "metadata": {
        "id": "2TC63YTwAxKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "id": "tIZ6z11r_0V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Range of values for some Loss functions:<br>\n",
        "\n",
        "- 0.00: Perfect probabilities<br>\n",
        "- < 0.02: Great probabilities<br>\n",
        "- < 0.05: In a good way<br>\n",
        "- < 0.20: Great<br>\n",
        "- \"> 0.30: Not great\"<br>\n",
        "- 1.00: Hell<br>\n",
        "- \"> 2.00 Something is not working\"<br>"
      ],
      "metadata": {
        "id": "i3a6F00XBMX0"
      }
    }
  ]
}