{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMx6un1+gs38CLgxkiH8oql",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/promptEngineering/blob/main/Gen_Text_Compare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/pytorch-transformers.git"
      ],
      "metadata": {
        "id": "UZCEIywKk6Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "id": "zcReapPljYLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-transformers"
      ],
      "metadata": {
        "id": "lxOTMChgjq5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "from pytorch_transformers import GPT2Tokenizer, GPT2LMHeadModel"
      ],
      "metadata": {
        "id": "HoGiRb9jkFwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finish the text:<br>\n",
        "\"What is the fastest car in the_________\""
      ],
      "metadata": {
        "id": "dPwB0j8ZkgbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using GPT2 to finish the text"
      ],
      "metadata": {
        "id": "MS0SQrOEksLP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuoF_zVfjKnT"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Encode a text inputs\n",
        "text = \"What is the fastest car in the\"\n",
        "indexed_tokens = tokenizer.encode(text)\n",
        "\n",
        "# Convert indexed tokens in a PyTorch tensor\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "pad_token_id=tokenizer.eos_token_id\n",
        "attention_mask=None,\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Set the model in evaluation mode to deactivate the DropOut modules\n",
        "model.eval()\n",
        "\n",
        "# If you have a GPU, put everything on cuda\n",
        "tokens_tensor = tokens_tensor.to('cuda')\n",
        "model.to('cuda')\n",
        "\n",
        "# Predict all tokens\n",
        "with torch.no_grad():\n",
        "    outputs = model(tokens_tensor)\n",
        "    predictions = outputs[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted next sub-word\n",
        "predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
        "predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])\n",
        "\n",
        "# Print the predicted word\n",
        "print(predicted_text)"
      ],
      "metadata": {
        "id": "2Ev5tESYkLJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gzF99cE2r-bJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete the text:<br>\n",
        "The unicorns had seemed to know each other almost as well as they did common humans. The study was published in Science Translational Medicine on May 6. What's more, researchers found that five percent of the unicorns recognized each other well. The study team thinks this might translate into a future where humans would be able to communicate more clearly with those known as super Unicorns. And if we're going to move ahead with that future, we've got to do it at least a"
      ],
      "metadata": {
        "id": "rgotMIsklEZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/pytorch-transformers/examples/pytorch/text-generation/run_generation.py \\\n",
        "        --model_type=gpt2 --length=100 --model_name_or_path=gpt2"
      ],
      "metadata": {
        "id": "Tdt53Wtjk4pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Completed text from GPT2\n",
        "little bit more quickly than before.\n",
        "<br><br>\n",
        "Advertisement\n",
        "<br><br>\n",
        "The research was led by scientists at Mount Sinai Hospital in New York City and the University of San Diego. That means everyone under five would be familiar with the possible high-level implications of super Unicorns for autistic individuals. All of the findings are based on video lectures posted online earlier this week by members of the SLI Universe Network, a group of neuroscientists working in the area of neurosciences.\n",
        "<br><br>\n",
        "The experiment started as a"
      ],
      "metadata": {
        "id": "03nKEcy-n_jX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5ULALoPOozRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Completed text from XLNet"
      ],
      "metadata": {
        "id": "Y246FAGknPP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/pytorch-transformers/examples/pytorch/text-generation/run_generation.py  \\\n",
        "    --model_type=xlnet \\\n",
        "    --length=100 \\\n",
        "    --model_name_or_path=xlnet-base-cased"
      ],
      "metadata": {
        "id": "I0oLwxASmzAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a couple of times a year.<eop> Radiation Atu?Was there a Radiation Notice for this day?Ernor Cummingson/News Today Communications Inc. was notified of this Notice. On October 29, 2014, the NAS issued its one of the most important actions for today (in Defense by Federal Government Assistants for Defense Administrations). A packet from the federal government and the NAS were submitted to the world. On September 12, 2014, the RRF issued a\n"
      ],
      "metadata": {
        "id": "tG1umn7coXaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Gn_gS4RWsEXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Completed text from transformer-XL"
      ],
      "metadata": {
        "id": "fEDDkiQ2sFL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/pytorch-transformers/examples/pytorch/text-generation/run_generation.py  \\\n",
        "    --model_type=transfo-xl \\\n",
        "    --length=100 \\\n",
        "    --model_name_or_path=transfo-xl-wt103"
      ],
      "metadata": {
        "id": "HDu7bE_Npa_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Completed by transformer-XL\n",
        "at least a thousand times before we do something stupid or stupid. \"These unicorns were considered by scientists to have unique abilities and typically were attacked by people who tried to cut them down. Apparently, these cheetahs were able to survive through a series of potions such as <unk>, which temporarily reduced the effectiveness of their initial attack on humans. Following a series of battles with some of the leopards that occurred as early as 1884, Russian authorities discovered in 1904 that Rasputin's experience with wild dogs and humans could have their"
      ],
      "metadata": {
        "id": "VHGMxA57p3Bu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UNRff3aarFaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment**<br>\n",
        "Open the file: /content/pytorch-transformers/examples/pytorch/text-generation/run_generation.py\n",
        "\n",
        "You'll see text used pad short input sequences.\n",
        "Change the text - search on Wikipedia, Reddit, or use any text that is at least 150 words long. <br>\n",
        "\n",
        "Re-run the notbook and see how the text changes."
      ],
      "metadata": {
        "id": "6L0ht1HsrG1Z"
      }
    }
  ]
}