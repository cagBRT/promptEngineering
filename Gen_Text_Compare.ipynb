{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNx0rIctaLe1ZBU3YlU6vdx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/promptEngineering/blob/main/Gen_Text_Compare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook the user gives three different language models the same text sequence and asks for the models to complete the text. <br>\n",
        "\n",
        "A comparison of the completed text from the models is interesting and can lead to a better understanding of each model. <br>\n",
        "\n",
        "The assignment asks the student to change the text for padding, then rerun the models and see the change in the completed text."
      ],
      "metadata": {
        "id": "Yse4iXLv0HmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/pytorch-transformers.git"
      ],
      "metadata": {
        "id": "UZCEIywKk6Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "id": "zcReapPljYLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-transformers"
      ],
      "metadata": {
        "id": "lxOTMChgjq5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "from pytorch_transformers import GPT2Tokenizer, GPT2LMHeadModel"
      ],
      "metadata": {
        "id": "HoGiRb9jkFwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "q19qUpIQuhL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finish the text:<br>\n",
        "\"What is the fastest car in the_________\""
      ],
      "metadata": {
        "id": "dPwB0j8ZkgbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using GPT2 to finish the text"
      ],
      "metadata": {
        "id": "MS0SQrOEksLP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuoF_zVfjKnT"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Encode a text inputs\n",
        "text = \"What is the fastest car in the\"\n",
        "indexed_tokens = tokenizer.encode(text)\n",
        "\n",
        "# Convert indexed tokens in a PyTorch tensor\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "pad_token_id=tokenizer.eos_token_id\n",
        "attention_mask=None,\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Set the model in evaluation mode to deactivate the DropOut modules\n",
        "model.eval()\n",
        "\n",
        "# If you have a GPU, put everything on cuda\n",
        "#tokens_tensor = tokens_tensor.to('cuda')\n",
        "#model.to('cuda')\n",
        "\n",
        "# Predict all tokens\n",
        "with torch.no_grad():\n",
        "    outputs = model(tokens_tensor)\n",
        "    predictions = outputs[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted next sub-word\n",
        "predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
        "predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])\n",
        "\n",
        "# Print the predicted word\n",
        "print(predicted_text)"
      ],
      "metadata": {
        "id": "2Ev5tESYkLJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gzF99cE2r-bJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we copy and paste the same text into three different models. <br>\n",
        "Compare the outputs and the length of time for each model"
      ],
      "metadata": {
        "id": "N_aPzOHbt0W8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete the text:<br>\n",
        "**Copy and paste the following text into the model prompt**<br>\n",
        "The unicorns had seemed to know each other almost as well as they did common humans. The study was published in Science Translational Medicine on May 6. What's more, researchers found that five percent of the unicorns recognized each other well. The study team thinks this might translate into a future where humans would be able to communicate more clearly with those known as super Unicorns. And if we're going to move ahead with that future, we've got to do it at least a"
      ],
      "metadata": {
        "id": "rgotMIsklEZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/pytorch-transformers/examples/pytorch/text-generation/run_generation.py \\\n",
        "        --model_type=gpt2 --length=100 --model_name_or_path=gpt2"
      ],
      "metadata": {
        "id": "Tdt53Wtjk4pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample of Completed text from GPT2\n",
        "little faster than when unicorns first entered human speech.<br>\n",
        "\n",
        "This is nice news to hear.<br>\n",
        "\n",
        "What do you think about Devesque's research? Is it worth it? Tell us what you think in the comments below or tweet @TheCultula_.<|endoftext|>"
      ],
      "metadata": {
        "id": "03nKEcy-n_jX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5ULALoPOozRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample of Completed text from XLNet"
      ],
      "metadata": {
        "id": "Y246FAGknPP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/pytorch-transformers/examples/pytorch/text-generation/run_generation.py  \\\n",
        "    --model_type=xlnet \\\n",
        "    --length=100 \\\n",
        "    --model_name_or_path=xlnet-base-cased"
      ],
      "metadata": {
        "id": "I0oLwxASmzAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bit first.<eop> August 26, 2017In Singapore, the White Party spent the second day on their frontline road. The White Party, preferably the White House, spent the first day in a military parking garage in North Galleria, Washington, a two-day military \"preview session.\" The Democratic Party of Russia, representing the coalition with the White House, spent the first day in a military parking garage, a parking yard in East North Galleria, a parking garage in North\n"
      ],
      "metadata": {
        "id": "tG1umn7coXaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Gn_gS4RWsEXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample of Completed text from transformer-XL"
      ],
      "metadata": {
        "id": "fEDDkiQ2sFL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll see a message about model variables, for now we can ignore them. <br>\n",
        "**You'll have to be patient for the text completion - this can take a few minutes.**"
      ],
      "metadata": {
        "id": "t34BUidQuBkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/pytorch-transformers/examples/pytorch/text-generation/run_generation.py  \\\n",
        "    --model_type=transfo-xl \\\n",
        "    --length=100 \\\n",
        "    --model_name_or_path=transfo-xl-wt103"
      ],
      "metadata": {
        "id": "HDu7bE_Npa_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Completed by transformer-XL\n",
        "dozen times. For example, if you lose your head or your body, then you can't fight as a horse or lead a more manly life. There's always a chance of something changing. Today, we're going to do it every day, and that's exactly where you want to go. The knight is going to stop hunting, and he's going to allow a unicorn to come down. The knight will be so beautiful that he'll start stalking you until you've killed him. <eos>"
      ],
      "metadata": {
        "id": "VHGMxA57p3Bu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UNRff3aarFaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment**<br>\n",
        "Open the file: /content/pytorch-transformers/examples/pytorch/text-generation/run_generation.py\n",
        "\n",
        "You'll see text used pad short input sequences.\n",
        "Change the text - search on Wikipedia, Reddit, or use any text that is at least 150 words long. <br>\n",
        "\n",
        "Re-run the notbook and see how the text changes."
      ],
      "metadata": {
        "id": "6L0ht1HsrG1Z"
      }
    }
  ]
}