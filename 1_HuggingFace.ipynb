{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOJ0aohM+qOJ3070jzD8d/c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/promptEngineering/blob/main/1_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/huggingface/notebooks/blob/main/transformers_doc/quicktour.ipynb"
      ],
      "metadata": {
        "id": "1JPpj5BMtv6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick tour<br>\n",
        "Get up and running with ðŸ¤— Transformers! Start using the pipeline() for rapid inference, and quickly load a pretrained model and tokenizer with an AutoClass to solve your text, vision or audio task.\n",
        "\n",
        "All code examples presented in the documentation have a toggle on the top left for PyTorch and TensorFlow. If not, the code is expected to work for both backends without any change."
      ],
      "metadata": {
        "id": "-xwrYtrOt-s4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk5inHQWjOWP"
      },
      "outputs": [],
      "source": [
        "# Transformers installation\n",
        "! pip install transformers datasets\n",
        "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
        "# ! pip install git+https://github.com/huggingface/transformers.git\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "id": "WRQ0c4IVmIeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline<br>\n",
        "pipeline() is the easiest way to use a pretrained model for a given task."
      ],
      "metadata": {
        "id": "et8uZcU1uKsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML('')\n"
      ],
      "metadata": {
        "id": "PYPRFHVdjbVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pipeline() supports many common tasks out-of-the-box:\n",
        "\n",
        "**Text:**\n",
        "\n",
        "Sentiment analysis: classify the polarity of a given text.<br>\n",
        "Text generation (in English): generate text from a given input.<br>\n",
        "Name entity recognition (NER): label each word with the entity it represents (person, date, location, etc.).<br>\n",
        "Question answering: extract the answer from the context, given some context and a question.<br>\n",
        "Fill-mask: fill in the blank given a text with masked words.<br>\n",
        "Summarization: generate a summary of a long sequence of text or document.<br>\n",
        "Translation: translate text into another language.<br>\n",
        "Feature extraction: create a tensor representation of the text.<br><br>\n",
        "\n",
        "**Image:**\n",
        "\n",
        "Image classification: classify an image.<br>\n",
        "Image segmentation: classify every pixel in an image.<br>\n",
        "Object detection: detect objects within an image.<br><br>\n",
        "**Audio:**\n",
        "\n",
        "Audio classification: assign a label to a given segment of audio.<br>\n",
        "Automatic speech recognition (ASR): transcribe audio data into text.<br>\n",
        "\n",
        "For more details about the pipeline() and associated tasks, refer to the documentation here."
      ],
      "metadata": {
        "id": "aP2NR0tbuPj9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline usage<br>\n",
        "In the following example, you will use the pipeline() for sentiment analysis."
      ],
      "metadata": {
        "id": "hYexlN2bu75j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "mgrQw6MLu3tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "id": "hGgqb_m1jgr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pipeline downloads and caches a default pretrained model and tokenizer for sentiment analysis. Now you can use the classifier on your target text:\n",
        "\n"
      ],
      "metadata": {
        "id": "_vtRd06PvFPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"We are very happy to show you the ðŸ¤— Transformers library.\")"
      ],
      "metadata": {
        "id": "Vqy1cUSujjr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more than one sentence, pass a list of sentences to the pipeline() which returns a list of dictionaries:\n",
        "\n"
      ],
      "metadata": {
        "id": "Yu0h4NZ1vJL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = classifier([\"We are very happy to show you the ðŸ¤— Transformers library.\", \"We hope you don't hate it.\"])\n",
        "for result in results:\n",
        "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
      ],
      "metadata": {
        "id": "iZHMgURojmrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pipeline() can also iterate over an entire dataset. "
      ],
      "metadata": {
        "id": "iizkE2APvRoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a pipeline() with the task you want to solve for and the model you want to use."
      ],
      "metadata": {
        "id": "p8p8xa4AwI-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")"
      ],
      "metadata": {
        "id": "ad6B8cQkjmtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, load a dataset (see the ðŸ¤— Datasets Quick Start for more details) you'd like to iterate over. For example, let's load the MInDS-14 dataset:"
      ],
      "metadata": {
        "id": "hpealt_twLlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Audio\n",
        "\n",
        "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\",download_mode=\"force_redownload\")"
      ],
      "metadata": {
        "id": "f9E0VKeDju15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to make sure that the sampling rate of the dataset matches the sampling rate facebook/wav2vec2-base-960h was trained on."
      ],
      "metadata": {
        "id": "tgKGyQ06wPVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))\n",
        "  "
      ],
      "metadata": {
        "id": "TV7nZ_a8ju4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audio files are automatically loaded and resampled when calling the \"audio\" column. Let's extract the raw waveform arrays of the first 4 samples and pass it as a list to the pipeline:\n",
        "\n"
      ],
      "metadata": {
        "id": "G9RtMpJQwS3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = speech_recognizer(dataset[:4][\"audio\"])\n",
        "print([d[\"text\"] for d in result])"
      ],
      "metadata": {
        "id": "dPXXmgH8tcr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "U7L2PrTWwbMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use another model and tokenizer in the pipeline<br>\n",
        "\n",
        "The pipeline() can accommodate any model from the Model Hub, making it easy to adapt the pipeline() for other use-cases. For example, if you'd like a model capable of handling French text, use the tags on the Model Hub to filter for an appropriate model. The top filtered result returns a multilingual BERT model fine-tuned for sentiment analysis. Great, let's use this model!"
      ],
      "metadata": {
        "id": "UrlZv6Mzwfsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\""
      ],
      "metadata": {
        "id": "EbnJACFgtoAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the AutoModelForSequenceClassification and AutoTokenizer to load the pretrained model and it's associated tokenizer (more on an AutoClass below):"
      ],
      "metadata": {
        "id": "C6LTYrFlw0On"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "1h6sb1TBtqeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then you can specify the model and tokenizer in the pipeline(), and apply the classifier on your target text:"
      ],
      "metadata": {
        "id": "lpvOhXhlw-zQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "cfZozWScttM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "classifier(\"Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ðŸ¤— Transformers.\")"
      ],
      "metadata": {
        "id": "2b4ByJhOtzx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you can't find a model for your use-case, you will need to fine-tune a pretrained model on your data. Take a look at our fine-tuning tutorial to learn how. Finally, after you've fine-tuned your pretrained model, please consider sharing it (see tutorial here) with the community on the Model Hub to democratize NLP for everyone! ðŸ¤—"
      ],
      "metadata": {
        "id": "o4rBFagsxCd9"
      }
    }
  ]
}