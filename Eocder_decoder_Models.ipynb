{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMCEKFNLz+l+C+0bE4JNsen",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/promptEngineering/blob/main/Eocder_decoder_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook gives examples of implementing Encoder models"
      ],
      "metadata": {
        "id": "ovFhUGtN5U5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -s https://github.com/cagBRT/promptEngineering.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "metadata": {
        "id": "xnjoiN8b34zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "id": "tv4-sNch3-jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers datasets"
      ],
      "metadata": {
        "id": "KO2v7xZMp2JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig, EncoderDecoderConfig, EncoderDecoderModel"
      ],
      "metadata": {
        "id": "0Ir3roHQ56Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configure the encoder and decoder**"
      ],
      "metadata": {
        "id": "SHNtxdu-5-pb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.\n",
        "\n",
        "BERT is conceptually simple and empirically powerful."
      ],
      "metadata": {
        "id": "YeewFT0UqdHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT is a model with absolute position embeddings so itâ€™s usually advised to pad the inputs on the right rather than the left.\n",
        "\n",
        "BERT was trained with the masked language modeling (MLM) and next sentence prediction (NSP) objectives. It is efficient at predicting masked tokens and at NLU in general, but is not optimal for text generation."
      ],
      "metadata": {
        "id": "nOsxJj7sqoOl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPLps1EJ3vds"
      },
      "outputs": [],
      "source": [
        "config_encoder = BertConfig()\n",
        "config_decoder = BertConfig()\n",
        "\n",
        "config = EncoderDecoderConfig.from_encoder_decoder_configs(config_encoder, config_decoder)\n",
        "model = EncoderDecoderModel(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizer"
      ],
      "metadata": {
        "id": "3LB5QvF16FP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Select a tokenizer**<br><br>\n",
        "**BertTokenizer**:\n",
        "BERT uses what is called a WordPiece tokenizer. It works by splitting words either into the full forms (e.g., one word becomes one token) or into word pieces â€” where one word can be broken into multiple tokens. An example of where this can be useful is where we have multiple forms of words.<br><br>\n",
        "BERT's creators noted a significant decrease in performance when using documents longer than 512 tokens. So, this limit was put to guard against low quality output"
      ],
      "metadata": {
        "id": "-sRSEK4S6Hbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "8a9CaP7o4M3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, EncoderDecoderModel"
      ],
      "metadata": {
        "id": "N14YFcWH69u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**patrickvonplaten/bert2bert_cnn_daily_mail**<br><br>\n",
        "This model is a warm-started BERT2BERT model fine-tuned on the CNN/Dailymail summarization dataset."
      ],
      "metadata": {
        "id": "UYJAQpVL7AwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load a fine-tuned seq2seq model and corresponding tokenizer\n",
        "model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")"
      ],
      "metadata": {
        "id": "MNDTRg2V68CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's perform inference on a long piece of text\n",
        "ARTICLE_TO_SUMMARIZE = (\n",
        "    \"PG&E stated it scheduled the blackouts in response to forecasts for high winds \"\n",
        "    \"amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were \"\n",
        "    \"scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\n",
        ")\n",
        "input_ids = tokenizer(ARTICLE_TO_SUMMARIZE, return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "hXWnJxYv4Pok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autoregressive models** predict future values based on past values. <br><br>\n",
        "For example: they are widely used in technical analysis to forecast future security prices."
      ],
      "metadata": {
        "id": "nDhi4djQ71bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# autoregressively generate summary (uses greedy decoding by default)\n",
        "generated_ids = model.generate(input_ids)\n",
        "generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "0BISXFkr9Caf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text"
      ],
      "metadata": {
        "id": "Gy9R7kF2riZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model summarized the text<br>\n",
        "Look at the summary the model generated.<br>\n",
        "Would you comsider this a good summary?\n"
      ],
      "metadata": {
        "id": "hJJZqr6Q8QV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8zbdRjDj9Yfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Summarization"
      ],
      "metadata": {
        "id": "PostzsI2-1iQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarization creates a shorter version of a document or an article that captures all the important information.\n",
        "\n",
        "Summarization can be:<br><br\n",
        "\n",
        ">**Extractive**: extract the most relevant information from a document.\n",
        "\n",
        ">**Abstractive**: generate new text that captures the most relevant information."
      ],
      "metadata": {
        "id": "p78GDlcq_DyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_text)"
      ],
      "metadata": {
        "id": "uLlIhpaM9ERl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's perform inference on a long piece of text\n",
        "ARTICLE_TO_SUMMARIZE = (\n",
        "    \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building,\"\n",
        "    \"and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on \"\n",
        "    \"each side. During its construction, the Eiffel Tower surpassed the Washington Monument to \"\n",
        "    \"become the tallest man-made structure in the world, a title it held for 41 years until the\"\n",
        "    \"Chrysler Building in New York City was finished in 1930. It was the first structure to reach\"\n",
        "    \"a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower\"\n",
        "    \"in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). \"\n",
        "    \"Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France\"\n",
        "    \"after the Millau Viaduct.\"\n",
        ")\n",
        "input_ids = tokenizer(ARTICLE_TO_SUMMARIZE, return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "QvMs_PE88eAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# autoregressively generate summary (uses greedy decoding by default)\n",
        "generated_ids = model.generate(input_ids)\n",
        "generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "VYVsuty17f-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_text)"
      ],
      "metadata": {
        "id": "XnYJF2dC7lO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MaLCjCUu9daL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a workaround to load from pytorch checkpoint\n",
        "from transformers import EncoderDecoderModel, TFEncoderDecoderModel\n",
        "\n",
        "_model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/bert2bert-cnn_dailymail-fp16\")\n",
        "\n",
        "_model.encoder.save_pretrained(\"./encoder\")\n",
        "_model.decoder.save_pretrained(\"./decoder\")\n",
        "\n",
        "model = TFEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
        "    \"./encoder\", \"./decoder\", encoder_from_pt=True, decoder_from_pt=True\n",
        ")\n",
        "# This is only for copying some specific attributes of this particular model.\n",
        "model.config = _model.config"
      ],
      "metadata": {
        "id": "tQmJYjL54X_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, EncoderDecoderModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")\n",
        "\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "input_ids = tokenizer(\n",
        "    \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side.During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was  finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft).Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\",\n",
        "    return_tensors=\"pt\",\n",
        ").input_ids\n",
        "\n",
        "labels = tokenizer(\n",
        "    \"the eiffel tower surpassed the washington monument to become the tallest structure in the world. it was the first structure to reach a height of 300 metres in paris in 1930. it is now taller than the chrysler building by 5. 2 metres ( 17 ft ) and is the second tallest free - standing structure in paris.\",\n",
        "    return_tensors=\"pt\",\n",
        ").input_ids\n",
        "\n",
        "# the forward function automatically creates the correct decoder_input_ids\n",
        "loss = model(input_ids=input_ids, labels=labels).loss"
      ],
      "metadata": {
        "id": "zObgrQD54hnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7C-6f7V4_qCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "vueC6hL5_sP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The smaller California state bill subset of the BillSum dataset from the ðŸ¤— Datasets library"
      ],
      "metadata": {
        "id": "mtLwJkBL_2Zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers datasets"
      ],
      "metadata": {
        "id": "At6IUhujAb7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "billsum = load_dataset(\"billsum\", split=\"ca_test\")"
      ],
      "metadata": {
        "id": "BY5dYYOG_sRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "billsum = billsum.train_test_split(test_size=0.2)"
      ],
      "metadata": {
        "id": "UDgCuuUS_7kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two fields that youâ€™ll want to use:\n",
        "\n",
        "text: the text of the bill whichâ€™ll be the input to the model.\n",
        "summary: a condensed version of text whichâ€™ll be the model target."
      ],
      "metadata": {
        "id": "c5UYDAgFAB0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "billsum[\"train\"][0]"
      ],
      "metadata": {
        "id": "aXGQ9BIr_-KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "QW32PJFWAEfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"summarize: \"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
        "\n",
        "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "pFLSAKRYAG4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_billsum = billsum.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "UBgq3ZZOAJcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint, return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "N_6su3HzA7q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install rouge_score\n",
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "kp6sn57gA908"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "id": "-uukMxYgBR2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer, AdamWeightDecay\n",
        "\n",
        "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)"
      ],
      "metadata": {
        "id": "O68-3HXwBR47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSeq2SeqLM\n",
        "\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "zVO7-HvmBW2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "ud1xUiJfBjuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_set = model.prepare_tf_dataset(\n",
        "    tokenized_billsum[\"train\"],\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_test_set = model.prepare_tf_dataset(\n",
        "    tokenized_billsum[\"test\"],\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "q6l7aN_tBayh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model.compile(optimizer=optimizer)  # No loss argument!"
      ],
      "metadata": {
        "id": "9L8XjHGNBwTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "\n",
        "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_train_set)"
      ],
      "metadata": {
        "id": "Qsd0iXbfBzIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"/content/cloned-repo\",\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "m5_VCUsoB8bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [metric_callback, push_to_hub_callback]"
      ],
      "metadata": {
        "id": "t6oz2RawB-ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=3, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "VEQC5IvnCAhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"summarize: The Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country. It'll lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. And no one making under $400,000 per year will pay a penny more in taxes.\""
      ],
      "metadata": {
        "id": "YOeZwSaRCCnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"stevhliu/my_awesome_billsum_model\")\n",
        "summarizer(text)"
      ],
      "metadata": {
        "id": "LmXFpRBrCQ3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"stevhliu/my_awesome_billsum_model\")\n",
        "inputs = tokenizer(text, return_tensors=\"tf\").input_ids"
      ],
      "metadata": {
        "id": "3wZbejl9CUNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSeq2SeqLM\n",
        "\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"stevhliu/my_awesome_billsum_model\")\n",
        "outputs = model.generate(inputs, max_new_tokens=100, do_sample=False)"
      ],
      "metadata": {
        "id": "aO0KQe_7CXTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "Y8E9yNXNCZd3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}