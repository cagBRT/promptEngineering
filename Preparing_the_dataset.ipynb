{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNPPUpOMlyF74/KNQktVaMx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/promptEngineering/blob/main/Preparing_the_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "download this [dataset](https://github.com/openai/openai-cookbook/blob/main/examples/data/fine_food_reviews_1k.csv)"
      ],
      "metadata": {
        "id": "60vx_6EPIItc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Create or login to your OpenAI account\n",
        "2. Go to API keys\n",
        "3. Create the key\n",
        "4. store it in a file called OpenAI Key\n",
        "5. Upload to this file structure\n",
        "6. Copy the path\n",
        "\n",
        "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\n",
        "\n"
      ],
      "metadata": {
        "id": "Zw8bSb2pbxeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "upload **fine_food_reviews_1k.csv** to the local directory"
      ],
      "metadata": {
        "id": "Dsizfz6LIU2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tiktoken -v"
      ],
      "metadata": {
        "id": "dEiirIIUH09g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai\n",
        "\n",
        "import os\n",
        "import openai"
      ],
      "metadata": {
        "id": "rsi-0LgKH8A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai[embeddings]\n"
      ],
      "metadata": {
        "id": "Wphvu1U-MU5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZMsXQ42HYDl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tiktoken\n",
        "\n",
        "from openai.embeddings_utils import get_embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding model parameters\n",
        "embedding_model = \"text-embedding-ada-002\"\n",
        "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
        "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191"
      ],
      "metadata": {
        "id": "Jd8xQKH7ICls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load & inspect dataset\n",
        "input_datapath = \"/content/fine_food_reviews_1k.csv\"  # to save space, we provide a pre-filtered dataset\n",
        "df = pd.read_csv(input_datapath, index_col=0)\n",
        "df = df[[\"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\n",
        "df = df.dropna()\n",
        "df[\"combined\"] = (\n",
        "    \"Title: \" + df.Summary.str.strip() + \"; Content: \" + df.Text.str.strip()\n",
        ")\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "j2F4puBLIFIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subsample to 1k most recent reviews and remove samples that are too long\n",
        "top_n = 1000\n",
        "df = df.sort_values(\"Time\").tail(top_n * 2)  # first cut to first 2k entries, assuming less than half will be filtered out\n",
        "df.drop(\"Time\", axis=1, inplace=True)\n",
        "\n",
        "encoding = tiktoken.get_encoding(embedding_encoding)\n",
        "\n",
        "# omit reviews that are too long to embed\n",
        "df[\"n_tokens\"] = df.combined.apply(lambda x: len(encoding.encode(x)))\n",
        "df = df[df.n_tokens <= max_tokens].tail(top_n)\n",
        "len(df)\n"
      ],
      "metadata": {
        "id": "mG7aThpAIrdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "TQdv34H8KdWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!export OPENAI_API_KEY=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\n",
        "openai.api_key = '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'"
      ],
      "metadata": {
        "id": "fukzSipHJJZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you have your API key set in your environment per the README: https://github.com/openai/openai-python#usage\n",
        "\n",
        "# This may take a few minutes\n",
        "df[\"embedding\"] = df.combined.apply(lambda x: get_embedding(x, engine=embedding_model))"
      ],
      "metadata": {
        "id": "KW4ctZYHIvmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"fine_food_reviews_with_embeddings_1k.csv\")"
      ],
      "metadata": {
        "id": "uEVEpKbqJ6jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "W9AeZhJGKljb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}